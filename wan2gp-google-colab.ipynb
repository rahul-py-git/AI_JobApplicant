{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "id": "KkEbh-Ct7xWk"
      },
      "id": "KkEbh-Ct7xWk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "77130695",
      "metadata": {
        "id": "77130695"
      },
      "source": [
        "## 1. Confirm the accelerator\n",
        "\n",
        "Choose `Runtime → Change runtime type` and select **GPU** before running anything else.\n",
        "\n",
        "If this cell raises an error, go back to `Runtime → Change runtime type`, pick **GPU** and save.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4039d142",
      "metadata": {
        "id": "4039d142",
        "outputId": "5b5e0c40-0525-414d-a995-f71e345778e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "GPU not detected. In Colab, open Runtime → Change runtime type, select GPU (or TPU if GPUs are unavailable), save, then rerun this cell.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2198566309.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nvidia-smi'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[1;32m   1027\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[0m\n\u001b[1;32m   1954\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0merr_filename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1955\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1956\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'nvidia-smi'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2198566309.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nvidia-smi'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     raise RuntimeError(\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;34m'GPU not detected. In Colab, open Runtime → Change runtime type, select GPU (or TPU if GPUs are unavailable), save, then rerun this cell.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     ) from exc\n",
            "\u001b[0;31mRuntimeError\u001b[0m: GPU not detected. In Colab, open Runtime → Change runtime type, select GPU (or TPU if GPUs are unavailable), save, then rerun this cell."
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "\n",
        "try:\n",
        "    subprocess.run(['nvidia-smi'], check=True)\n",
        "except Exception as exc:\n",
        "    raise RuntimeError(\n",
        "        'GPU not detected. In Colab, open Runtime → Change runtime type, select GPU (or TPU if GPUs are unavailable), save, then rerun this cell.'\n",
        "    ) from exc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f584c5cb",
      "metadata": {
        "id": "f584c5cb"
      },
      "source": [
        "# Wan2GP on Google Colab\n",
        "\n",
        "Sets up [Wan2GP](https://github.com/deepbeepmeep/Wan2GP) in a fresh GPU-backed Colab session.\n",
        "\n",
        "Run the cells in order to prepare the runtime, install dependencies, and launch the Gradio interface. Click on the link in the output from the last cell to launch the app in your browser.\n",
        "\n",
        "> **Colab VRAM note:** the free tier usually assigns a 15 GB T4 GPU. Most Wan2GP models exceed that budget; the Wan 2.2 TextImage2Video FastWan model works, producing roughly a 5 second 480p clip in about 8 minutes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56f52fd5",
      "metadata": {
        "id": "56f52fd5"
      },
      "source": [
        "## 2. Configure the workspace path\n",
        "\n",
        "Choose where Wan2GP should be installed. Update `WAN2GP_ROOT` if you prefer a different location.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2d7ee132",
      "metadata": {
        "id": "2d7ee132",
        "outputId": "3f19f3a1-0773-406d-f1d2-92ea3d97b4bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wan2GP will be installed to: /content/Wan2GP\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "WAN2GP_ROOT = Path('/content/Wan2GP').resolve()\n",
        "print(f'Wan2GP will be installed to: {WAN2GP_ROOT}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3594ffa",
      "metadata": {
        "id": "e3594ffa"
      },
      "source": [
        "## 3. Download or update Wan2GP\n",
        "\n",
        "Clone the repository if it is not present yet; otherwise pull the latest changes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a3dc4c56",
      "metadata": {
        "id": "a3dc4c56"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "repo_url = 'https://github.com/deepbeepmeep/Wan2GP.git'\n",
        "if WAN2GP_ROOT.exists():\n",
        "    print('Repository already exists. Pulling latest changes...')\n",
        "    subprocess.run(['git', '-C', str(WAN2GP_ROOT), 'pull'], check=True)\n",
        "else:\n",
        "    subprocess.run(['git', 'clone', repo_url, str(WAN2GP_ROOT)], check=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95ea607f",
      "metadata": {
        "id": "95ea607f"
      },
      "source": [
        "## 4. Install system dependencies\n",
        "\n",
        "Install shared libraries needed for video and audio processing. If you see a warning about skipping an extra repository, it is safe to ignore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ef235d0f",
      "metadata": {
        "id": "ef235d0f",
        "outputId": "2d47d716-2cee-4835-92c7-6810ab0689b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args=['sudo', 'apt-get', 'install', '-y', '--no-install-recommends', 'ffmpeg', 'libglib2.0-0', 'libgl1', 'libportaudio2'], returncode=0)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import os, subprocess\n",
        "\n",
        "env = os.environ.copy()\n",
        "env['DEBIAN_FRONTEND'] = 'noninteractive'\n",
        "\n",
        "subprocess.run(['sudo', 'apt-get', 'update', '-qq'], check=True, env=env)\n",
        "subprocess.run([\n",
        "    'sudo', 'apt-get', 'install', '-y', '--no-install-recommends',\n",
        "    'ffmpeg', 'libglib2.0-0', 'libgl1', 'libportaudio2'\n",
        "], check=True, env=env)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f619664",
      "metadata": {
        "id": "1f619664"
      },
      "source": [
        "## 5. Install Python dependencies\n",
        "\n",
        "Install PyTorch, xformers and Wan2GP's Python packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d7093e37",
      "metadata": {
        "id": "d7093e37",
        "outputId": "c2880f46-03b4-4456-8217-187bf0e8d439",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args=['/usr/bin/python3', '-m', 'pip', 'install', '-r', '/content/Wan2GP/requirements.txt'], returncode=0)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import os, subprocess, sys\n",
        "\n",
        "env = os.environ.copy()\n",
        "env.setdefault('DEBIAN_FRONTEND', 'noninteractive')\n",
        "\n",
        "subprocess.run([sys.executable, '-m', 'pip', 'install', '--upgrade', 'pip', 'setuptools', 'wheel'], check=True, env=env)\n",
        "subprocess.run([sys.executable, '-m', 'pip', 'install', 'torch==2.8.0', 'torchvision', 'torchaudio', '--index-url', 'https://download.pytorch.org/whl/cu128'], check=True, env=env)\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"xformers==0.0.32.post2\", \"--index-url\", \"https://download.pytorch.org/whl/cu128\"],\n",
        "               check=True, env=env)\n",
        "subprocess.run([sys.executable, '-m', 'pip', 'install', '-r', str(WAN2GP_ROOT / 'requirements.txt')], check=True, env=env)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E59tDTseywCw"
      },
      "source": [
        "## 5b. Force a headless matplotlib backend\n",
        "\n",
        "Ensure Wan2GP's preprocessing tools use the headless Agg backend so Step 6 launches cleanly in Colab.\n"
      ],
      "id": "E59tDTseywCw"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "779d7612",
      "metadata": {
        "id": "779d7612",
        "outputId": "64ee4a30-c14b-4e0b-9b4e-9980273d1c0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replaced TkAgg with Agg in interact_tools.py.\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Replace the TkAgg backend with the headless Agg backend if present.\n",
        "target = WAN2GP_ROOT / 'preprocessing/matanyone/tools/interact_tools.py'\n",
        "needle = \"matplotlib.use('TkAgg')\"\n",
        "replacement = \"matplotlib.use('Agg')\"\n",
        "\n",
        "if not target.exists():\n",
        "    print(f'Skipping: {target} not found.')\n",
        "else:\n",
        "    text = target.read_text()\n",
        "    if replacement in text:\n",
        "        print('Agg backend already set; no change needed.')\n",
        "    elif needle in text:\n",
        "        target.write_text(text.replace(needle, replacement, 1))\n",
        "        print('Replaced TkAgg with Agg in interact_tools.py.')\n",
        "    else:\n",
        "        print('Backend call not found; no change made.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e7d6487",
      "metadata": {
        "id": "5e7d6487"
      },
      "source": [
        "## 6. Launch Wan2GP\n",
        "\n",
        "Run the Gradio interface. You will find the gradio link in the output. Click on the link to access the UI. Keep the cell running to stay connected; stop it with the square **Stop** button when you are finished."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cb423194",
      "metadata": {
        "id": "cb423194",
        "outputId": "e3fa7286-3e2c-4e26-9480-4c2f24844b18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Launching Wan2GP…\n",
            "2026-02-20 16:20:32.472927: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1771604432.806868   13805 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1771604432.896254   13805 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1771604433.523625   13805 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771604433.523793   13805 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771604433.523797   13805 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771604433.523800   13805 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-20 16:20:33.580216: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Wan2GP/wgp.py\", line 47, in <module>\n",
            "    from shared.attention import get_attention_modes, get_supported_attention_modes\n",
            "  File \"/content/Wan2GP/shared/attention.py\", line 9, in <module>\n",
            "    major, minor = torch.cuda.get_device_capability(None)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 600, in get_device_capability\n",
            "    prop = get_device_properties(device)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 616, in get_device_properties\n",
            "    _lazy_init()  # will define _get_device_properties\n",
            "    ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 412, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "Wan2GP stopped (return code: 1).\n"
          ]
        }
      ],
      "source": [
        "import os, subprocess, sys, threading, time\n",
        "\n",
        "env = os.environ.copy()\n",
        "env.setdefault('WAN_CACHE_DIR', str(WAN2GP_ROOT / 'models'))\n",
        "cmd = [\n",
        "    sys.executable,\n",
        "    '-u',\n",
        "    'wgp.py',\n",
        "    '--listen',\n",
        "    '--server-port', '7860',\n",
        "    '--share',\n",
        "    '--profile', '5',\n",
        "]\n",
        "print('Launching Wan2GP…')\n",
        "process = subprocess.Popen(\n",
        "    cmd,\n",
        "    cwd=str(WAN2GP_ROOT),\n",
        "    env=env,\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    text=True,\n",
        "    bufsize=1,\n",
        ")\n",
        "stop_event = threading.Event()\n",
        "\n",
        "def keepalive():\n",
        "    while not stop_event.is_set():\n",
        "        time.sleep(45)\n",
        "        if stop_event.is_set():\n",
        "            break\n",
        "        print('[keepalive] Notebook cell still running…')\n",
        "\n",
        "keepalive_thread = threading.Thread(target=keepalive, daemon=True)\n",
        "keepalive_thread.start()\n",
        "\n",
        "try:\n",
        "    for line in iter(process.stdout.readline, ''):\n",
        "        if not line:\n",
        "            break\n",
        "        print(line, end='')\n",
        "except KeyboardInterrupt:\n",
        "    print('Stopping Wan2GP…')\n",
        "    process.terminate()\n",
        "finally:\n",
        "    stop_event.set()\n",
        "    process.wait()\n",
        "    keepalive_thread.join(timeout=1)\n",
        "    print(f'Wan2GP stopped (return code: {process.returncode}).')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Wan2GP on Colab",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}